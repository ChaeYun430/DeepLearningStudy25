{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMlC5AlD9ys4wnafTnFHWU+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChaeYun430/MachineLearningStudy25/blob/master/scikit_learn/cross_validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "# === 데이터 세트 활용 ===\n",
        "iris = load_iris()\n",
        "iris_feature = iris.feature_names\n",
        "iris_feature_data  = iris.data\n",
        "iris_label = iris.target_names\n",
        "iris_label_data =  iris.target"
      ],
      "metadata": {
        "id": "FWnJIJwD4Uex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 과적합(Overfitting)\n",
        "# 모델이 학습 데이터에만 과도하게 최적화되어, 실제 예측을 다른 데이터로 수행할 경우에는 예측 성능이 과도하게 떨어지는 것\n",
        "\n",
        "# 교차 검증\n",
        "# 데이터 편중을 막기 위해 별도의 여러 세트로 구성된 학습 데이터 세트와 검증 데이터 세트에서 학습과 평가를 수행하는 것"
      ],
      "metadata": {
        "id": "4Iv8fu7KpxOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== K 폴드 교차 검증 =====\n",
        "# K개의 데이터 폴드 세트를 만들어서 K번만큼 각 폴드 세트에 학습과 검증 평가를 반복적으로 수행하는 방법\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "kfold = KFold(n_splits=5)\n",
        "cv_accuracy = []\n",
        "print(iris_feature_data.shape[0])\n",
        "\n",
        "n_iter = 0\n",
        "for train_index, test_index in kfold.split(iris_feature_data):\n",
        "  X_train, X_test = iris_feature_data[train_index], iris_feature_data[test_index]\n",
        "  y_train, y_test = iris_label_data[train_index], iris_label_data[test_index]\n",
        "\n",
        "  dt_clf = DecisionTreeClassifier()\n",
        "  dt_clf.fit(X_train, y_train)\n",
        "  pred = dt_clf.predict(X_test)\n",
        "  n_iter += 1\n",
        "\n",
        "  accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
        "  train_size = X_train.shape[0]\n",
        "  test_size = X_train.shape[0]\n",
        "  print(n_iter, accuracy, train_size, test_size, test_index)\n",
        "  cv_accuracy.append(accuracy)\n",
        "\n",
        "print(np.mean(cv_accuracy))"
      ],
      "metadata": {
        "id": "x3fBdsq5tNXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 불균형한 분포도를 가진 레이블(결정 클래스) 데이터 집합 =====\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import pandas as pd\n",
        "\n",
        "iris_df = pd.DataFrame(data = iris_feature_data, columns = iris_feature)\n",
        "iris_df['label'] = iris_label_data\n",
        "\n",
        "kfold = KFold(n_splits=3)\n",
        "skfold = StratifiedKFold(n_splits=3)\n",
        "\n",
        "for train_index, test_index in kfold.split(iris_df):\n",
        "  y_train = iris_df['label'].iloc[train_index]\n",
        "  y_test = iris_df['label'].iloc[test_index]\n",
        "  print(y_train.value_counts())\n",
        "\n",
        "\n",
        "for train_index, test_index in skfold.split(iris_df, iris_df['label']):\n",
        "  y_train = iris_df['label'].iloc[train_index]\n",
        "  y_test = iris_df['label'].iloc[test_index]\n",
        "  print(y_train.value_counts())"
      ],
      "metadata": {
        "id": "lZJKOqPy0lss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Stratified K 폴드 =====\n",
        "# 원본 데이터의 레이블 분포를 먼저 고려한 뒤 이 분포와 동일하게 학습과 검증 데이터 세트를 분배\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5)\n",
        "n_iter = 0\n",
        "\n",
        "for train_index, test_index in skf.split(iris_feature_data, iris_label_data):\n",
        "\n",
        "  X_train, X_test = iris_feature_data[train_index], iris_feature_data[test_index]\n",
        "  y_train, y_test = iris_label_data[train_index], iris_label_data[test_index]\n",
        "\n",
        "  dt_clf = DecisionTreeClassifier()\n",
        "  dt_clf.fit(X_train, y_train)\n",
        "  pred = dt_clf.predict(X_test)\n",
        "  n_iter += 1\n",
        "\n",
        "  accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
        "  train_size = X_train.shape[0]\n",
        "  test_size = X_train.shape[0]\n",
        "  print(n_iter, accuracy, train_size, test_size, test_index)\n",
        "\n",
        "  cv_accuracy.append(accuracy)\n",
        "\n",
        "print(np.mean(cv_accuracy))"
      ],
      "metadata": {
        "id": "c8xTN9Ubp86g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 교차 검증 API =====\n",
        "# cross_val_score(), cross_validate()\n",
        "# scoring : 예측 성능 평가 지표\n",
        "# cv : 교차 검증 폴드 수\n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import numpy as np\n",
        "\n",
        "scores = cross_val_score(DecisionTreeClassifier(), iris_feature_data, iris_label_data, scoring='accuracy', cv = 3)\n",
        "print(np.round(scores, 4))\n",
        "print(np.round(np.mean(scores), 4))"
      ],
      "metadata": {
        "id": "NUNSbU6J723T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== 교차 검증 기반 하이퍼 파라미터의 최적 값 찾기 =====\n",
        "# 알고리즘에 사용되는 하이퍼 파라미터를 순차적으로 입력하면서 편리하게 최적의 파라미터를 도출\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_feature_data, iris_label_data, test_size= 0.2)\n",
        "\n",
        "hyper_params = {'min_samples_split':[2, 3], 'max_depth':[1, 2, 3]}\n",
        "grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid = hyper_params, cv = 3, refit = True)\n",
        "print(type(grid_search))\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "scores_dict = grid_search.cv_results_\n",
        "scores_df = pd.DataFrame(scores_dict)\n",
        "display(scores_df)\n",
        "print(grid_search.best_params_, grid_search.best_score_)\n",
        "\n",
        "estimator = grid_search.best_estimator_\n",
        "pred = estimator.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, pred)\n",
        "print(accuracy)"
      ],
      "metadata": {
        "id": "CpL8uhnG_YWj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}